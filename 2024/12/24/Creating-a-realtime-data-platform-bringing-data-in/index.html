<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  
  <title>Creating a realtime data platform - bringing data in | Fasih Khatib</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="In the first part we saw the overall design of the system. In the second part we created a dataset that we can work with. In this post we’ll look at the first category of components and these are the">
<meta property="og:type" content="article">
<meta property="og:title" content="Creating a realtime data platform - bringing data in">
<meta property="og:url" content="http://fasihkhatib.com/2024/12/24/Creating-a-realtime-data-platform-bringing-data-in/index.html">
<meta property="og:site_name" content="Fasih Khatib">
<meta property="og:description" content="In the first part we saw the overall design of the system. In the second part we created a dataset that we can work with. In this post we’ll look at the first category of components and these are the">
<meta property="og:locale">
<meta property="og:image" content="http://fasihkhatib.com/2024/12/24/Creating-a-realtime-data-platform-bringing-data-in/table.png">
<meta property="og:image" content="http://fasihkhatib.com/2024/12/24/Creating-a-realtime-data-platform-bringing-data-in/pinot.png">
<meta property="article:published_time" content="2024-12-24T13:45:02.000Z">
<meta property="article:modified_time" content="2024-12-25T12:56:47.360Z">
<meta property="article:author" content="Fasih Khatib">
<meta property="article:tag" content="architecture">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://fasihkhatib.com/2024/12/24/Creating-a-realtime-data-platform-bringing-data-in/table.png">
  
    <link rel="alternate" href="/atom.xml" title="Fasih Khatib" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Fasih Khatib</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
          <a class="main-nav-link" href="/about">About Me</a>
        
          <a class="main-nav-link" href="/principles">Guiding Principles</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://fasihkhatib.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-Creating-a-realtime-data-platform-bringing-data-in" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2024/12/24/Creating-a-realtime-data-platform-bringing-data-in/" class="article-date">
  <time datetime="2024-12-24T13:45:02.000Z" itemprop="datePublished">2024-12-24</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      Creating a realtime data platform - bringing data in
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>In the first part we saw the overall design of the system. In the second part we created a dataset that we can work with. In this post we’ll look at the first category of components and these are the ones that bring the data into the platform. We’ll see how we can stream data from the database using Debezium and store it in Pinot realtime tables.  </p>
<h2 id="Before-we-begin"><a href="#Before-we-begin" class="headerlink" title="Before we begin"></a>Before we begin</h2><p>The setup is still Dockerized and now has containers for Debezium, Kafka, and Pinot. In a nutshell, we’ll stream data from the Postgres instance into Kafka using Debezium and then write it to Pinot tables.  </p>
<h2 id="Getting-started"><a href="#Getting-started" class="headerlink" title="Getting started"></a>Getting started</h2><p>In the first part of the series we briefly looked at Debezium. To recap, Debezium is a platform for change data capture. It consists of connectors which capture change data from the database and emit them as events into Kafka. Which database tables to monitor and which Kafka topic to write them to are specified as a part of the connector’s configuration. This configuration is written as a JSON object and sent to a specfic endpoint to spawn a new connector.  </p>
<p>We’ll begin by creating configuration for a connector which will monitor all the tables in the database and route each of them to a dedicated Kafka topic.  </p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">{</span></span><br><span class="line">    <span class="attr">"name"</span><span class="punctuation">:</span> <span class="string">"order_service"</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">"config"</span><span class="punctuation">:</span> <span class="punctuation">{</span></span><br><span class="line">        <span class="attr">"connector.class"</span><span class="punctuation">:</span> <span class="string">"io.debezium.connector.postgresql.PostgresConnector"</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">"database.hostname"</span><span class="punctuation">:</span> <span class="string">"db"</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">"database.user"</span><span class="punctuation">:</span> <span class="string">"postgres"</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">"database.password"</span><span class="punctuation">:</span> <span class="string">"my-secret-pw"</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">"database.dbname"</span><span class="punctuation">:</span> <span class="string">"postgres"</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">"database.server.name"</span><span class="punctuation">:</span> <span class="string">"postgres"</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">"plugin.name"</span><span class="punctuation">:</span> <span class="string">"pgoutput"</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">"publication.autocreate.mode"</span><span class="punctuation">:</span> <span class="string">"filtered"</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">"time.precision.mode"</span><span class="punctuation">:</span> <span class="string">"connect"</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">"tombstones.on.delete"</span><span class="punctuation">:</span> <span class="string">"false"</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">"snapshot.mode"</span><span class="punctuation">:</span> <span class="string">"no_data"</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">"heartbeat.interval.ms"</span><span class="punctuation">:</span> <span class="string">"1000"</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">"transforms"</span><span class="punctuation">:</span> <span class="string">"route"</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">"transforms.route.type"</span><span class="punctuation">:</span> <span class="string">"org.apache.kafka.connect.transforms.RegexRouter"</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">"transforms.route.regex"</span><span class="punctuation">:</span> <span class="string">"([^.]+)\\.([^.]+)\\.([^.]+)"</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">"transforms.route.replacement"</span><span class="punctuation">:</span> <span class="string">"$3"</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">"event.processing.failure.handling.mode"</span><span class="punctuation">:</span> <span class="string">"skip"</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">"producer.override.compression.type"</span><span class="punctuation">:</span> <span class="string">"snappy"</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">"signal.data.collection"</span><span class="punctuation">:</span> <span class="string">"debezium.signal"</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">"topic.prefix"</span><span class="punctuation">:</span> <span class="string">"microservice"</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">"decimal.handling.mode"</span><span class="punctuation">:</span> <span class="string">"float"</span></span><br><span class="line">    <span class="punctuation">}</span></span><br><span class="line"><span class="punctuation">}</span></span><br></pre></td></tr></table></figure>  
<p>There are two main parts to this configuration - <code>name</code> and <code>config</code>. The <code>name</code> is the name we’ve given to the connector. The <code>config</code> contains the actual configuration of the connector. We specify quite a few things in the <code>config</code> object. We specify the class of the connector which is the fully qualified name of the Java class, the credentials to connect to the database, whether or not to take a snapshot, how to route the data to the appropriate Kafka topics, and how to pass signals to Debezium.  </p>
<p>While most of the configuration is self-explanatory, we’ll look closely at the ones related to snapshot, signalling, and routing. We set the snapshot mode to <code>no_data</code> which means that the connector will stream historical rows from the database. The only rows that will be emitted are the ones created or updated after the connector began running. We’ll use this setting in conjunction with signals to incrementally snapshot the tables we’re interested in. Signals are a way to modify the behavior of the connector, or to trigger a one-time action like taking an ad-hoc snapshot. When we combine <code>no_data</code> with signals, we can tell Debezium to selectively snapshot the tables we’re interested in. The <code>signal.data.collection</code> property specifies the name of the table which the connector will monitor for any signals that are sent to it.</p>
<p>Finally, we specify a route transform. We do this by writing a regex which matches against the fully qualified name of the table, and extracts only the table name. This allows us to send the data from every table into a dedicated Kafka topic of its own.  </p>
<p>Notice how we’ve not specified which tables to monitor. Since it is a Postgres database, the connector will monitor all the tables in all the schemas within the database and stream them. Now that the configuration is created, we’ll POST it to the appropriate endpoint to create the connector.   </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">curl -H "Content-Type: application/json" -XPOST -d @tables/002-orders/debezium.json localhost:8083/connectors | jq .</span><br></pre></td></tr></table></figure>  
<p>Now that the connector is created, we will signal it to initiate a snapshot. Signals are sent to the connector using rows inserted into the table. We’ll execute the following <code>INSERT</code> query to tell the connector to take a snapshot of the <code>orders</code> table.  </p>
<figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> debezium.signal </span><br><span class="line"><span class="keyword">VALUES</span> (</span><br><span class="line">    gen_random_uuid()::TEXT,</span><br><span class="line">    <span class="string">'execute-snapshot'</span>,</span><br><span class="line">    <span class="string">'{"data-collections": [".*\\.orders"], "type": "incremental"}'</span></span><br><span class="line">);</span><br></pre></td></tr></table></figure>  
<p>The row tells the connector to initiate a snapshot, as indicated by <code>execute-snapshot</code>, and stream historical rows from the <code>orders</code> table in all the schemas within the database. It is an incremental snapshot so it will happen in batches. If we <code>docker exec</code> into the Kafka container and use the console consumer, we’ll find that all the rows eventually get streamed to the topic. The command to show it is given below.  </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[kafka@kafka ~]$ kafka-console-consumer.sh --bootstrap-server kafka:9092 --topic orders --from-beginning | wc -l</span><br><span class="line">^CProcessed a total of 5000 messages</span><br></pre></td></tr></table></figure>  
<p>We can compare this with the row count in the table using the following SQL command.  </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SELECT COUNT(*) FROM public.orders;</span><br><span class="line">| count |</span><br><span class="line">|-------|</span><br><span class="line">|  5000 |</span><br></pre></td></tr></table></figure>  
<p>Now that the data is in Kafka, we’ll move on to how to stream it into a Pinot table. Before we get to that, we’ll look at what a table and schema are in Pinot.  </p>
<p>A table in Pinot is similar to a table in a relational database. It has rows and columns where each column has a datatype. Tables are where data is stored in Pinot. Every table in Pinot has an associated schema and it is in the schema where the columns and their datatypes are defined. Tables can be realtime, where they store data from a streaming source such as Kafka. They can be offline, where they load data from batch sources. Or they can be hybrid, where they load data from both a batch source and a streaming source. Both the schema and table are defined as JSON.  </p>
<p>Let’s start by creating the schema.  </p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">{</span></span><br><span class="line">  <span class="attr">"schemaName"</span><span class="punctuation">:</span> <span class="string">"orders"</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">"enableColumnBasedNullHandling"</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">"dimensionFieldSpecs"</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">{</span></span><br><span class="line">      <span class="attr">"name"</span><span class="punctuation">:</span> <span class="string">"id"</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">"dataType"</span><span class="punctuation">:</span> <span class="string">"STRING"</span></span><br><span class="line">    <span class="punctuation">}</span><span class="punctuation">,</span></span><br><span class="line">    <span class="punctuation">{</span></span><br><span class="line">      <span class="attr">"name"</span><span class="punctuation">:</span> <span class="string">"source"</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">"dataType"</span><span class="punctuation">:</span> <span class="string">"JSON"</span></span><br><span class="line">    <span class="punctuation">}</span></span><br><span class="line">  <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">"dateTimeFieldSpecs"</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="punctuation">{</span></span><br><span class="line">      <span class="attr">"name"</span><span class="punctuation">:</span> <span class="string">"created_at"</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">"dataType"</span><span class="punctuation">:</span> <span class="string">"LONG"</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">"format"</span><span class="punctuation">:</span> <span class="string">"1:MILLISECONDS:EPOCH"</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">"granularity"</span><span class="punctuation">:</span> <span class="string">"1:MILLISECONDS"</span></span><br><span class="line">    <span class="punctuation">}</span></span><br><span class="line">  <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">"primaryKeyColumns"</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="string">"id"</span></span><br><span class="line">  <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">"metricFieldSpecs"</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">}</span></span><br></pre></td></tr></table></figure>  
<p>The schema defines a few things. It defines the name of the schema. This will also become the name of the table. Next, it defines the fields that will be present in the table. We’ve defined <code>id</code>, <code>source</code>, and <code>created_at</code>. The first two are specified in <code>dimensionFieldSpecs</code> and specify a column which becomes a dimension for any metric. The <code>created_at</code> field is specified in <code>dateTimeFieldSpecs</code> since it specifies a time column; Debezium will send timestamp columns as milliseconds since epoch. We’ve specified <code>id</code> as the primary key. Finally, <code>enableColumnBasedNullHandling</code> allows columns to have null values in them.</p>
<p>Once the schema is defined, we can create the table configuration.  </p>
<img src="/2024/12/24/Creating-a-realtime-data-platform-bringing-data-in/table.png" class="">  
<p>The configuration of tbe table is more involved than the schema so we’ll go over it one key at a time. We begin by specifying the <code>tableName</code> as “orders”. This matches the name of the schema. We specify <code>tableType</code> as “REALTIME” since the data we’re going to ingest comes from a Kafka topic. The <code>query</code> key specifies properties related to query execution. The <code>segmentsConfig</code> key specifies properties related to segments like the time column to use for creating a segment. The <code>tenants</code> key specifies the tenants for this table. A tenant is a logical namespace which restricts where the cluster processes queries on the table. The <code>tableIndexConfig</code> defines the indexing related information for the table. The <code>metadata</code> key specifies the metadata for this table. The <code>upsertCconfig</code> key specifies configuration for upserting into the table. The <code>ingestionConfig</code> key defines where we’d be ingesting data from and what field-level transformations we’d like to apply. The <code>routing</code> key defines properties that determine how the broker selects the servers to route.  </p>
<p>The part of the configuration we’ll specifically look at is the <code>ingestionConfig</code> and <code>upsertConfig</code>. First, <code>ingestionConfig</code>.</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">{</span></span><br><span class="line">  <span class="attr">"ingestionConfig"</span><span class="punctuation">:</span> <span class="punctuation">{</span></span><br><span class="line">    <span class="attr">"streamIngestionConfig"</span><span class="punctuation">:</span> <span class="punctuation">{</span></span><br><span class="line">      <span class="attr">"streamConfigMaps"</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">{</span></span><br><span class="line">          <span class="attr">"realtime.segment.flush.threshold.rows"</span><span class="punctuation">:</span> <span class="string">"0"</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">"stream.kafka.decoder.prop.format"</span><span class="punctuation">:</span> <span class="string">"JSON"</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">"key.serializer"</span><span class="punctuation">:</span> <span class="string">"org.apache.kafka.common.serialization.ByteArraySerializer"</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">"stream.kafka.decoder.class.name"</span><span class="punctuation">:</span> <span class="string">"org.apache.pinot.plugin.stream.kafka.KafkaJSONMessageDecoder"</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">"streamType"</span><span class="punctuation">:</span> <span class="string">"kafka"</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">"value.serializer"</span><span class="punctuation">:</span> <span class="string">"org.apache.kafka.common.serialization.ByteArraySerializer"</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">"stream.kafka.consumer.type"</span><span class="punctuation">:</span> <span class="string">"LOWLEVEL"</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">"realtime.segment.flush.threshold.segment.rows"</span><span class="punctuation">:</span> <span class="string">"50000"</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">"stream.kafka.broker.list"</span><span class="punctuation">:</span> <span class="string">"kafka:9092"</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">"realtime.segment.flush.threshold.time"</span><span class="punctuation">:</span> <span class="string">"3600000"</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">"stream.kafka.consumer.factory.class.name"</span><span class="punctuation">:</span> <span class="string">"org.apache.pinot.plugin.stream.kafka20.KafkaConsumerFactory"</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">"stream.kafka.consumer.prop.auto.offset.reset"</span><span class="punctuation">:</span> <span class="string">"smallest"</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">"stream.kafka.topic.name"</span><span class="punctuation">:</span> <span class="string">"orders"</span></span><br><span class="line">        <span class="punctuation">}</span></span><br><span class="line">      <span class="punctuation">]</span></span><br><span class="line">    <span class="punctuation">}</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">"transformConfigs"</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">      <span class="punctuation">{</span></span><br><span class="line">        <span class="attr">"columnName"</span><span class="punctuation">:</span> <span class="string">"id"</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">"transformFunction"</span><span class="punctuation">:</span> <span class="string">"jsonPath(payload, '$.after.id')"</span></span><br><span class="line">      <span class="punctuation">}</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">{</span></span><br><span class="line">        <span class="attr">"columnName"</span><span class="punctuation">:</span> <span class="string">"source"</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">"transformFunction"</span><span class="punctuation">:</span> <span class="string">"jsonPath(payload, '$.after')"</span></span><br><span class="line">      <span class="punctuation">}</span><span class="punctuation">,</span></span><br><span class="line">      <span class="punctuation">{</span></span><br><span class="line">        <span class="attr">"columnName"</span><span class="punctuation">:</span> <span class="string">"created_at"</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">"transformFunction"</span><span class="punctuation">:</span> <span class="string">"jsonPath(payload, '$.after.created_at')"</span></span><br><span class="line">      <span class="punctuation">}</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line">  <span class="punctuation">}</span></span><br><span class="line"><span class="punctuation">}</span></span><br></pre></td></tr></table></figure>  
<p>In the <code>ingestionConfig</code> we specify the the Kafka topics to read from. In the snippet above, we’ve specified the “orders” topic. We also specify field-level transformations in <code>transformConfigs</code>. Here we extract the <code>id</code>, <code>source</code>, and <code>created_at</code> fields from the JSON payload generated by Debezium.  </p>
<p>With the schema and table defined, we’ll POST them to the appropriate endpoints using curl. The following two commands create the schema followed by the table.  </p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">curl -F schemaName=@tables/002-orders/orders_schema.json localhost:9000/schemas | jq .</span><br><span class="line">curl -XPOST -H 'Content-Type: application/json' -d @tables/002-orders/orders_table.json localhost:9000/tables | jq .</span><br></pre></td></tr></table></figure>  
<p>Once the table is created, it will begin ingesting data from the “orders” Kafka topic. We can view this data by opening the Pinot query console. Notice how the <code>source</code> column contains the entire “after” payload generated by Debezium.</p>
<img src="/2024/12/24/Creating-a-realtime-data-platform-bringing-data-in/pinot.png" class="">  
<p>That’s it. That’s how to stream data using Debezium into Pinot.</p>
<link rel="stylesheet" href="/css/spoiler.css" type="text/css"><script src="/js/spoiler.js" type="text/javascript" async></script>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://fasihkhatib.com/2024/12/24/Creating-a-realtime-data-platform-bringing-data-in/" data-id="cm5v12xq6000kqlrug61x7t0l" data-title="Creating a realtime data platform - bringing data in" class="article-share-link">Share</a>
      
        <a href="http://fasihkhatib.com/2024/12/24/Creating-a-realtime-data-platform-bringing-data-in/#disqus_thread" class="article-comment-link">Comments</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/architecture/" rel="tag">architecture</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2024/12/26/Creating-a-realtime-data-platform-evolving-the-schema/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Creating a realtime data platform - evolving the schema
        
      </div>
    </a>
  
  
    <a href="/2024/12/22/Creating-a-realtime-data-platform-creating-the-data/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Creating a realtime data platform - creating the data</div>
    </a>
  
</nav>

  
</article>


<section id="comments">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>

</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/algorithms/" style="font-size: 10px;">algorithms</a> <a href="/tags/architecture/" style="font-size: 20px;">architecture</a> <a href="/tags/category-theory/" style="font-size: 12.86px;">category theory</a> <a href="/tags/clojure/" style="font-size: 10px;">clojure</a> <a href="/tags/compilers/" style="font-size: 12.86px;">compilers</a> <a href="/tags/epi/" style="font-size: 12.86px;">epi</a> <a href="/tags/functional-programming/" style="font-size: 20px;">functional programming</a> <a href="/tags/machine-learning/" style="font-size: 14.29px;">machine learning</a> <a href="/tags/math/" style="font-size: 11.43px;">math</a> <a href="/tags/misc/" style="font-size: 15.71px;">misc</a> <a href="/tags/python/" style="font-size: 12.86px;">python</a> <a href="/tags/scala/" style="font-size: 18.57px;">scala</a> <a href="/tags/scalaz/" style="font-size: 17.14px;">scalaz</a> <a href="/tags/testing/" style="font-size: 10px;">testing</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2025/01/12/Creating-a-realtime-data-platform-indexing/">Creating a realtime data platform - indexing</a>
          </li>
        
          <li>
            <a href="/2025/01/10/Creating-a-realtime-data-platform-embedding/">Creating a realtime data platform - embedding</a>
          </li>
        
          <li>
            <a href="/2025/01/06/Creating-a-realtime-data-platform-visualization/">Creating a realtime data platform - visualization</a>
          </li>
        
          <li>
            <a href="/2025/01/04/Creating-a-realtime-data-platform-orchestration/">Creating a realtime data platform - orchestration</a>
          </li>
        
          <li>
            <a href="/2025/01/02/Creating-a-realtime-data-platform-SQL/">Creating a realtime data platform - SQL</a>
          </li>
        
          <li>
            <a href="/2024/12/27/Creating-a-realtime-data-platform-nullability/">Creating a realtime data platform - nullability</a>
          </li>
        
          <li>
            <a href="/2024/12/26/Creating-a-realtime-data-platform-evolving-the-schema/">Creating a realtime data platform - evolving the schema</a>
          </li>
        
          <li>
            <a href="/2024/12/24/Creating-a-realtime-data-platform-bringing-data-in/">Creating a realtime data platform - bringing data in</a>
          </li>
        
          <li>
            <a href="/2024/12/22/Creating-a-realtime-data-platform-creating-the-data/">Creating a realtime data platform - creating the data</a>
          </li>
        
          <li>
            <a href="/2024/12/18/Creating-a-data-wrehouse-with-Apache-Pinot-and-Debezium/">Creating a realtime data platform - the design</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2025 Fasih Khatib<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
    <a href="/about" class="mobile-nav-link">About Me</a>
  
    <a href="/principles" class="mobile-nav-link">Guiding Principles</a>
  
</nav>
    
<script>
  var disqus_shortname = 'https-thescalaguy-github-io';
  
  var disqus_url = 'http://fasihkhatib.com/2024/12/24/Creating-a-realtime-data-platform-bringing-data-in/';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>



<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->
</body>
</html>